{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temporo spatial join\n",
    "\n",
    "Method : \n",
    "1. Temporo Spatial Join : for each year - Spatial join between Senf & Seidl and the others datasets \n",
    "3. Group creation : groupby on the Senf & Seidl index. (One group per index)\n",
    "2. Group work : \n",
    "    - Computing weights for each row\n",
    "    - Computing score per disturbance type\n",
    "    - Save group to a dict with the index as key\n",
    "    - Create row with year, class, score, tree_type, essence  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading \n",
    "import geopandas as gpd\n",
    "epsg = 'epsg:2154'\n",
    "senfseidl = gpd.read_parquet('../data/processed_datasets/SenfSeidl_joined_EPSG4326_FR.parquet').to_crs(epsg)\n",
    "nfi = gpd.read_parquet('../data/processed_datasets/NFI_2003-2021_EPSG4326_FR.parquet').to_crs(epsg)\n",
    "hm = gpd.read_parquet('../data/processed_datasets/health-monitoring_2007-2023_EPSG4326_FR.parquet').to_crs(epsg)\n",
    "dfde = gpd.read_parquet('../data/processed_datasets/DFDE_1984_2021_EPSG4326_FR.parquet').to_crs(epsg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#compute weights\n",
    "def spatial_weight(x) -> float:\n",
    "    if x <= 1:\n",
    "        return 1\n",
    "    else: \n",
    "        return 1 - (x-1)/9 \n",
    "    \n",
    "def temporal_weight(x) -> float:\n",
    "    if x <= 3:\n",
    "        return 1 - x/12\n",
    "    else: \n",
    "        return 0.75 * (1 - (x-3)/3)\n",
    "\n",
    "from thefuzz import fuzz\n",
    "\n",
    "def compute_tree_coherence(row_tt, row_e, ref_tt, ref_e) -> float:\n",
    "\n",
    "    for essence in ref_e.split(','):\n",
    "        if fuzz.token_set_ratio(row_e.lower(), essence.lower()) > 80:\n",
    "            return 1\n",
    "        \n",
    "    if row_tt.lower() == ref_tt.lower():\n",
    "        return 0.75 \n",
    "    \n",
    "    if row_tt.lower() == 'mixed' or ref_tt.lower() == 'mixed':\n",
    "        return 0.5\n",
    "\n",
    "    return 0.25 \n",
    "\n",
    "#compute proba per class\n",
    "dict_isin = {\n",
    "    'Fire': ['Fire'],\n",
    "    'Storm': ['Storm', 'Storm,Biotic'],\n",
    "    'Drought': ['Drought'],\n",
    "    'Biotic-dieback': ['Biotic-dieback', 'Biotic', 'Storm,Biotic', 'Other'],\n",
    "    'Biotic-mortality': ['Biotic-mortality', 'Biotic', 'Storm,Biotic', 'Other'],\n",
    "    'Tree-logging': ['Tree-logging', 'Other'],\n",
    "    'Other': ['Other']\n",
    "}\n",
    "\n",
    "def compute_proba_per_class(gdf):\n",
    "    dclasses = {}\n",
    "    present_classes = [ k for k in gdf['class'].unique() if k != 'Other']\n",
    "    if present_classes == []:\n",
    "        return {'Other': gdf['p'].mean()}\n",
    "\n",
    "    for c in [k for k,v in dict_isin.items() if set(v).intersection(set(present_classes))]:\n",
    "        cond = gdf['class'].isin(dict_isin[c])\n",
    "        for_ = gdf[cond]['p'].sum()\n",
    "        against_ = gdf[~cond]['p'].sum()\n",
    "        dclasses[c] = (for_ - against_) / len(gdf)\n",
    "\n",
    "    return dclasses \n",
    "\n",
    "def compute_class_p_spread(d):\n",
    "    #sort dict by value descending \n",
    "    d = {k: v for k, v in sorted(d.items(), key=lambda item: item[1], reverse=True)}\n",
    "    keys = list(d.keys()) \n",
    "    values = list(d.values())\n",
    "    spread = values[0] - values[1] if len(values) > 1 else np.nan \n",
    "\n",
    "    return keys[0], values[0], spread\n",
    "\n",
    "def wrapper_class_proba_spread(group):\n",
    "    dclasses = compute_proba_per_class(group)\n",
    "    max_key, max_value, spread = compute_class_p_spread(dclasses)\n",
    "    #return dataframe with index\n",
    "    return pd.DataFrame({'class': max_key, 'p': max_value, 'spread': spread}, index=group.index[[0]]) \n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def compute_weight_on_merge(row):\n",
    "    # spatial distance, spatial weight, temporal distance, temporal weight, tree correspondance weight, overall accuracy\n",
    "    if row['dataset'] == 'senfseidl':\n",
    "        return 0, 1, 0, 1, 1, 0.88, 0.88 \n",
    "    elif row['dataset'] == 'dfde':\n",
    "        sd = (row['area'] / 1e6)** (1/2) / 35\n",
    "        oa = 0.95\n",
    "    elif row['dataset'] in ['hm', 'nfi']:\n",
    "        sd = row['sd'] / 1e3\n",
    "        oa = 0.9\n",
    "\n",
    "    if row['dataset'] in ['dfde', 'nfi']:\n",
    "        td = min(abs(row['year_y'] - row['start_date'].year), abs(row['end_date'].year - row['year_y']))\n",
    "    elif row['dataset'] == 'hm':\n",
    "        td = min(abs(row['year_y'] - row['year']), abs(row['year'] - row['year_y']))\n",
    "    \n",
    "    tc = compute_tree_coherence(row['tree_type'], row['essence'], row['tree_type_y'], row['essence_y'])\n",
    "    sw = spatial_weight(sd)\n",
    "    tw = temporal_weight(td)\n",
    "\n",
    "    return sd, sw, td, tw, tc, oa, np.mean([sw,tw,tc]) * oa\n",
    "\n",
    "def get_prob(df):\n",
    "    return df.apply(compute_weight_on_merge, axis=1, result_type='expand')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing \n",
    "\n",
    "Performing geometric computation here so we can entirely rely on Dask.DataFrame later for big data processing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Senf & Seidl\n",
    "senfseidl.year = senfseidl.year.astype(int)\n",
    "\n",
    "number_to_class = {\n",
    "    1:'Storm,Biotic', \n",
    "    2:'Fire',\n",
    "    3:'Other'\n",
    "}\n",
    "\n",
    "senfseidl['class'] = senfseidl['cause'].map(number_to_class)\n",
    "senf_seidl_col = ['year', 'geometry', 'class', 'tree_type', 'essence']\n",
    "senfseidl = senfseidl[senf_seidl_col]\n",
    "senfseidl.drop_duplicates(inplace=True)\n",
    "senfseidl.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DFDE\n",
    "\n",
    "#class\n",
    "dict_class = {\n",
    "    'Fire': ['Fire'],\n",
    "    'Storm': ['Wind'],\n",
    "    'Drought': ['Summer drought', 'Frost'],\n",
    "    'Biotic': [\n",
    "        'Ips typographus', 'Pissodes spp.', 'Bark beetles', 'Bombix desparate',\n",
    "        'Zeiraphera diniana', 'Biotic', 'Insects', 'Other insects', 'Biotic;Abiotic',\n",
    "        'Pityogenes chalcographus', 'Tetropium luridum;Tetropium fuscum',\n",
    "        'Ips acuminatus', 'Tomicus piniperda;Tomicus minor',\n",
    "        'Phaenops cyanea', 'Pissodes pini', 'Ips cembrae',\n",
    "        'Tetropium gabrieli', 'Agrilus biguttatus', 'Agrilus viridis',\n",
    "        'Xyloterus lineatus', 'Erannis defoliaria',\n",
    "        'Operophtera brumata;Operophtera fagata', 'Lymantria dispar',\n",
    "        'Thaumetopoea processionea', 'Hylobius abietis',\n",
    "        'Melolontha hippocastani;Melolontha melolontha',\n",
    "        'Microtus agrestis;Microtus arvalis;Clethrionomys glareolus',\n",
    "        'Arvicola terrestris', 'Lophodermium seditiosum',\n",
    "        'Sphaeropsis sapinea', 'Heterobasidion annosum',\n",
    "        'Armillaria mellea', 'Chalara fraxinea;Hymenoscyphus fraxineus',\n",
    "        'Beech decline', 'Oak decline', 'Viscum album', 'Ips sexdentatus'\n",
    "    ],\n",
    "    'Tree-logging': [],\n",
    "    'Other': ['Accident']\n",
    "}\n",
    "\n",
    "def get_class(x):\n",
    "    for key, values in dict_class.items():\n",
    "        if x in values:\n",
    "            return key\n",
    "    return 'Other'\n",
    "\n",
    "dfde['class'] = dfde['cause'].apply(get_class)\n",
    "\n",
    "#geometry\n",
    "dname_geom = {k:v for k,v in zip(dfde['name'].tolist(), dfde['geometry'].tolist())}\n",
    "dname_geom = {k:v.buffer(5000).simplify(5000) for k,v in dname_geom.items()}\n",
    "dname_area = {k:v.area for k,v in dname_geom.items()}\n",
    "\n",
    "#drop duplicates \n",
    "dfde.drop_duplicates(subset=['name', 'start_date', 'end_date', 'essence', 'cause', 'notes'], inplace=True)\n",
    "dfde['geometry'] = dfde['name'].apply(lambda x: dname_geom[x]) \n",
    "\n",
    "#compute area here !\n",
    "dfde['area'] = dfde['name'].apply(lambda x: dname_area[x])\n",
    "\n",
    "#clean date\n",
    "import pandas as pd\n",
    "dfde['start_date'] = pd.to_datetime(dfde['start_date'])\n",
    "dfde['end_date'] = pd.to_datetime(dfde['end_date'])\n",
    "\n",
    "#keep_col\n",
    "dfde_col = ['start_date', 'end_date', 'geometry', 'class', 'tree_type', 'essence', 'cause', 'notes', 'area']\n",
    "dfde = dfde[dfde_col]\n",
    "\n",
    "dfde.dropna(inplace=True)\n",
    "dfde.drop_duplicates(inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nfi \n",
    "\n",
    "#filtering\n",
    "nfi = nfi[ (nfi['probability'] >= 0.1) ]\n",
    "nfi = nfi[ ~((nfi['class'] == 'Tree-logging')&(nfi['intensity']==0)) ]\n",
    "\n",
    "#correct start_date\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "def get_start_date(row):\n",
    "    if not pd.isnull(row['start_date']):\n",
    "        return row['start_date']\n",
    "    else:\n",
    "        return row['end_date'] - timedelta(days=5*365.25)\n",
    "    \n",
    "\n",
    "nfi['start_date'] = nfi.apply(get_start_date, axis=1)\n",
    "\n",
    "#keep col \n",
    "nfi_col = ['start_date', 'end_date', 'geometry', 'class', 'tree_type', 'essence']\n",
    "nfi = nfi[nfi_col]\n",
    "\n",
    "nfi.dropna(inplace=True)\n",
    "nfi.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hm\n",
    "def get_class(x):\n",
    "    if x  == 'biotic-factor':\n",
    "        return 'Biotic'\n",
    "    else :\n",
    "        return 'Other'\n",
    "    \n",
    "hm['class'] = hm['class'].apply(get_class)\n",
    "hm['year'] = hm['year'].astype(int)\n",
    "hm.drop_duplicates(inplace=True)\n",
    "hm.dropna(inplace=True)\n",
    "\n",
    "hm.rename(columns={'LIB_Problème principal':'cause', 'Remarques':'notes'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RD Joining\n",
    "\n",
    "Joining ~ 10s / year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#full Dask -> 20s \n",
    "# with sjoin_nearest and sd computation -> 8s  \n",
    "import dask_geopandas as dgpd\n",
    "import dask.dataframe as dd\n",
    "\n",
    "years = senfseidl['year'].unique()\n",
    "\n",
    "temporal_buffer = 5 #years \n",
    "spatial_buffer = 5000 #meters\n",
    "# nfi.geometry = nfi.geometry.buffer(spatial_buffer)\n",
    "# hm.geometry = hm.geometry.buffer(spatial_buffer)\n",
    "\n",
    "nfi['dataset'] = 'nfi'\n",
    "hm['dataset'] = 'hm'\n",
    "dfde['dataset'] = 'dfde'\n",
    "senfseidl['dataset'] = 'senfseidl'\n",
    "\n",
    "year = 2010\n",
    "\n",
    "senfseidl_year = senfseidl[senfseidl['year'] == year]\n",
    "nfi_year = nfi[(nfi['start_date'].dt.year >= year - temporal_buffer) & (nfi['end_date'].dt.year <= year + temporal_buffer)]\n",
    "hm_year = hm[(hm['year'] >= year - temporal_buffer) & (hm['year'] <= year + temporal_buffer)]\n",
    "dfde_year = dfde[(dfde['start_date'].dt.year >= year - temporal_buffer) & (dfde['end_date'].dt.year <= year + temporal_buffer)]\n",
    "\n",
    "senfseidl_year_ = dgpd.from_geopandas(senfseidl_year, npartitions=10)\n",
    "# nfi_year = dgpd.from_geopandas(nfi_year, npartitions=10)\n",
    "# hm_year = dgpd.from_geopandas(hm_year, npartitions=10)\n",
    "dfde_year_ = dgpd.from_geopandas(dfde_year, npartitions=10)\n",
    "\n",
    "# senfseidl_nfi_year = nfi_year.sjoin(senfseidl_year)\n",
    "# senfseidl_hm_year = hm_year.sjoin(senfseidl_year)\n",
    "senfseidl_hm_year = hm_year.sjoin_nearest(senfseidl_year, max_distance=spatial_buffer, distance_col='sd')\n",
    "senfseidl_nfi_year = nfi_year.sjoin_nearest(senfseidl_year, max_distance=spatial_buffer, distance_col='sd')\n",
    "senfseidl_dfde_year = dfde_year_.sjoin(senfseidl_year_)\n",
    "\n",
    "#concat with dask_geopandas\n",
    "import dask.dataframe as dd\n",
    "concatenation = dd.concat([senfseidl_nfi_year, senfseidl_hm_year, senfseidl_dfde_year], axis=0).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354418, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthurcalvi/Venv/DiAtDaJo/lib/python3.9/site-packages/geopandas/geodataframe.py:1538: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    }
   ],
   "source": [
    "#entire dataset -> 2.3s\n",
    "print(concatenation.shape)\n",
    "\n",
    "col = ['start_date', 'end_date', 'geometry', 'year_left', 'class_left', 'tree_type_left', 'essence_left', 'dataset_left', 'cause', 'notes', 'area', 'sd']\n",
    "all_index_right = concatenation['index_right'].unique()\n",
    "concatenation = concatenation[['index_right']+col]\n",
    "rename = {c: c.split('_left')[0] for c in col}\n",
    "concatenation = concatenation.rename(columns=rename)\n",
    "\n",
    "senfseidl_year['index_right'] = senfseidl_year.index\n",
    "\n",
    "#l'order of senfseidl_year and co is important. If we want to ise iloc[0] on the group to retrieve senfseidl row, we have to stick to this order.\n",
    "concatenation = dd.concat([senfseidl_year.loc[all_index_right], concatenation], axis=0).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>geometry</th>\n",
       "      <th>class</th>\n",
       "      <th>tree_type</th>\n",
       "      <th>essence</th>\n",
       "      <th>dataset</th>\n",
       "      <th>index_right</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>cause</th>\n",
       "      <th>notes</th>\n",
       "      <th>area</th>\n",
       "      <th>sd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2424927</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>POLYGON ((318824.872 6257012.037, 318794.980 6...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>larch</td>\n",
       "      <td>senfseidl</td>\n",
       "      <td>2424927</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424928</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>POLYGON ((318846.967 6257104.615, 318876.859 6...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>larch</td>\n",
       "      <td>senfseidl</td>\n",
       "      <td>2424928</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424949</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>POLYGON ((320572.848 6259442.594, 320483.176 6...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>mixed,laricio pine, black pine</td>\n",
       "      <td>senfseidl</td>\n",
       "      <td>2424949</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424950</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>POLYGON ((320353.214 6259541.838, 320383.105 6...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>deciduous oaks,laricio pine, black pine</td>\n",
       "      <td>senfseidl</td>\n",
       "      <td>2424950</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424953</th>\n",
       "      <td>2010.0</td>\n",
       "      <td>POLYGON ((315790.192 6261751.147, 315849.974 6...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Broadleaf</td>\n",
       "      <td>broadleaf</td>\n",
       "      <td>senfseidl</td>\n",
       "      <td>2424953</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64876</th>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (777643.312 6415230.264)</td>\n",
       "      <td>Biotic-dieback</td>\n",
       "      <td>Broadleaf</td>\n",
       "      <td>European Ash</td>\n",
       "      <td>nfi</td>\n",
       "      <td>2531745</td>\n",
       "      <td>2010-12-27 18:00:00</td>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2032.403655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64886</th>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (553066.658 6200340.091)</td>\n",
       "      <td>Storm</td>\n",
       "      <td>Broadleaf</td>\n",
       "      <td>Pedunculate Oak</td>\n",
       "      <td>nfi</td>\n",
       "      <td>2503011</td>\n",
       "      <td>2010-12-27 18:00:00</td>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1650.712193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64890</th>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (193749.856 6855715.893)</td>\n",
       "      <td>Tree-logging</td>\n",
       "      <td>Broadleaf</td>\n",
       "      <td>Pedunculate Oak</td>\n",
       "      <td>nfi</td>\n",
       "      <td>2426031</td>\n",
       "      <td>2010-12-27 18:00:00</td>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4609.385803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64891</th>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (834333.883 6736479.550)</td>\n",
       "      <td>Biotic-dieback</td>\n",
       "      <td>Broadleaf</td>\n",
       "      <td>Pedunculate Oak</td>\n",
       "      <td>nfi</td>\n",
       "      <td>2542883</td>\n",
       "      <td>2010-12-27 18:00:00</td>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1852.003375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64910</th>\n",
       "      <td>NaN</td>\n",
       "      <td>POINT (757943.456 6330480.461)</td>\n",
       "      <td>Biotic-dieback</td>\n",
       "      <td>Broadleaf</td>\n",
       "      <td>Downy Oak</td>\n",
       "      <td>nfi</td>\n",
       "      <td>2529174</td>\n",
       "      <td>2010-12-27 18:00:00</td>\n",
       "      <td>2015-12-28</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2229.323687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>446654 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           year                                           geometry  \\\n",
       "2424927  2010.0  POLYGON ((318824.872 6257012.037, 318794.980 6...   \n",
       "2424928  2010.0  POLYGON ((318846.967 6257104.615, 318876.859 6...   \n",
       "2424949  2010.0  POLYGON ((320572.848 6259442.594, 320483.176 6...   \n",
       "2424950  2010.0  POLYGON ((320353.214 6259541.838, 320383.105 6...   \n",
       "2424953  2010.0  POLYGON ((315790.192 6261751.147, 315849.974 6...   \n",
       "...         ...                                                ...   \n",
       "64876       NaN                     POINT (777643.312 6415230.264)   \n",
       "64886       NaN                     POINT (553066.658 6200340.091)   \n",
       "64890       NaN                     POINT (193749.856 6855715.893)   \n",
       "64891       NaN                     POINT (834333.883 6736479.550)   \n",
       "64910       NaN                     POINT (757943.456 6330480.461)   \n",
       "\n",
       "                  class  tree_type                                  essence  \\\n",
       "2424927           Other      Mixed                                    larch   \n",
       "2424928           Other      Mixed                                    larch   \n",
       "2424949           Other      Mixed           mixed,laricio pine, black pine   \n",
       "2424950           Other      Mixed  deciduous oaks,laricio pine, black pine   \n",
       "2424953           Other  Broadleaf                                broadleaf   \n",
       "...                 ...        ...                                      ...   \n",
       "64876    Biotic-dieback  Broadleaf                             European Ash   \n",
       "64886             Storm  Broadleaf                          Pedunculate Oak   \n",
       "64890      Tree-logging  Broadleaf                          Pedunculate Oak   \n",
       "64891    Biotic-dieback  Broadleaf                          Pedunculate Oak   \n",
       "64910    Biotic-dieback  Broadleaf                                Downy Oak   \n",
       "\n",
       "           dataset  index_right          start_date   end_date cause notes  \\\n",
       "2424927  senfseidl      2424927                 NaT        NaT  <NA>  <NA>   \n",
       "2424928  senfseidl      2424928                 NaT        NaT  <NA>  <NA>   \n",
       "2424949  senfseidl      2424949                 NaT        NaT  <NA>  <NA>   \n",
       "2424950  senfseidl      2424950                 NaT        NaT  <NA>  <NA>   \n",
       "2424953  senfseidl      2424953                 NaT        NaT  <NA>  <NA>   \n",
       "...            ...          ...                 ...        ...   ...   ...   \n",
       "64876          nfi      2531745 2010-12-27 18:00:00 2015-12-28  <NA>  <NA>   \n",
       "64886          nfi      2503011 2010-12-27 18:00:00 2015-12-28  <NA>  <NA>   \n",
       "64890          nfi      2426031 2010-12-27 18:00:00 2015-12-28  <NA>  <NA>   \n",
       "64891          nfi      2542883 2010-12-27 18:00:00 2015-12-28  <NA>  <NA>   \n",
       "64910          nfi      2529174 2010-12-27 18:00:00 2015-12-28  <NA>  <NA>   \n",
       "\n",
       "         area           sd  \n",
       "2424927   NaN          NaN  \n",
       "2424928   NaN          NaN  \n",
       "2424949   NaN          NaN  \n",
       "2424950   NaN          NaN  \n",
       "2424953   NaN          NaN  \n",
       "...       ...          ...  \n",
       "64876     NaN  2032.403655  \n",
       "64886     NaN  1650.712193  \n",
       "64890     NaN  4609.385803  \n",
       "64891     NaN  1852.003375  \n",
       "64910     NaN  2229.323687  \n",
       "\n",
       "[446654 rows x 13 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methode 1 : Concat -> Groupby -> Apply\n",
    "\n",
    "- Version normal : ok \n",
    "- Version vectorisée : 2x plus lent\n",
    "- Version parallelisée avec Joblib : 2x plus lent\n",
    "- Version avec Dask : ne fonctionne pas\n",
    "\n",
    "25min / year \n",
    "\n",
    "40 year ~ 17h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weight(row, reference):\n",
    "    # spatial distance, spatial weight, temporal distance, temporal weight, tree correspondance weight, overall accuracy\n",
    "    if row['dataset'] == 'senfseidl':\n",
    "        return 0, 1, 0, 1, 1, 0.88, 0.88 \n",
    "    elif row['dataset'] == 'dfde':\n",
    "        sd = (row['area'] / 1e6)** (1/2) / 35\n",
    "        oa = 0.95\n",
    "    elif row['dataset'] in ['hm', 'nfi']:\n",
    "        sd = row['sd'] / 1e3\n",
    "        oa = 0.9\n",
    "\n",
    "    if row['dataset'] in ['dfde', 'nfi']:\n",
    "        td = min(abs(reference['year'] - row['start_date'].year), abs(row['end_date'].year - reference['year']))\n",
    "    elif row['dataset'] == 'hm':\n",
    "        td = min(abs(reference['year'] - row['year']), abs(row['year'] - reference['year']))\n",
    "    \n",
    "    tc = compute_tree_coherence(row['tree_type'], row['essence'], reference['tree_type'], reference['essence'])\n",
    "    sw = spatial_weight(sd)\n",
    "    tw = temporal_weight(td)\n",
    "\n",
    "    return sd, sw, td, tw, tc, oa, sw * tw * tc * oa\n",
    "\n",
    "def wrappper_weight_group(group):\n",
    "    reference = group.iloc[0]\n",
    "    group[['sd', 'sw', 'td', 'tw', 'tc', 'oa', 'p']] = group.apply(lambda x: compute_weight(x,reference), axis=1, result_type='expand')\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(354418, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthurcalvi/Venv/DiAtDaJo/lib/python3.9/site-packages/geopandas/geodataframe.py:1538: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n",
      "/Users/arthurcalvi/Venv/DiAtDaJo/lib/python3.9/site-packages/distributed/client.py:3148: UserWarning: Sending large graph of size 366.14 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "92236"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#simplifying code : using concat and groupby for appending the reference (senfseidl) row. \n",
    "\n",
    "#entire dataset -> 2.3s\n",
    "co = concatenation\n",
    "print(co.shape)\n",
    "\n",
    "col = ['start_date', 'end_date', 'geometry', 'year_left', 'class_left', 'tree_type_left', 'essence_left', 'dataset_left', 'cause', 'notes', 'area', 'sd']\n",
    "all_index_right = co['index_right'].unique()\n",
    "co = co[['index_right']+col]\n",
    "rename = {c: c.split('_left')[0] for c in col}\n",
    "co = co.rename(columns=rename)\n",
    "\n",
    "senfseidl_year['index_right'] = senfseidl_year.index\n",
    "\n",
    "#l'order of senfseidl_year and co is important. If we want to ise iloc[0] on the group to retrieve senfseidl row, we have to stick to this order.\n",
    "groups = dd.concat([senfseidl_year.loc[all_index_right], co], axis=0).compute().groupby(by='index_right')\n",
    "len(groups)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La version vectorisée n'est pas plus rapide car les groupes sont petits. De 2 à 50 lignes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrapper(group):\n",
    "    reference = group.iloc[0]\n",
    "    group[['sd', 'sw', 'td', 'tw', 'tc', 'oa', 'p']] = group.apply(lambda x: compute_weight(x, reference), axis=1, result_type='expand')\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#130 000 -> 22min\n",
    "disturbances = groups.apply(wrapper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1000 -> 14.5s \n",
    "#10000 -> 2min 14s\n",
    "from itertools import islice\n",
    "for name, group in islice(groups, 1000):\n",
    "    vectorized_compute_weight(group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1000 -> 6.6s \n",
    "#10000 -> 1mins \n",
    "#130 000 -> 13min\n",
    "from itertools import islice\n",
    "for name, group in islice(groups, 1000):\n",
    "    group[['sd', 'sw', 'td', 'tw', 'tc', 'oa', 'p']] = group.apply(lambda x: compute_weight(x, group.iloc[0]), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8787/status\n"
     ]
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "\n",
    "client = Client() \n",
    "\n",
    "print(client.dashboard_link) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthurcalvi/Venv/DiAtDaJo/lib/python3.9/site-packages/distributed/client.py:3148: UserWarning: Sending large graph of size 366.15 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n",
      "2023-10-17 09:34:33,194 - distributed.worker - WARNING - Compute Failed\n",
      "Key:       ('shuffle-transfer-a1a63667780cb7392e35539ec39715c9', 0)\n",
      "Function:  shuffle_transfer\n",
      "args:      (           year  ... _partitions\n",
      "2424927  2010.0  ...           1\n",
      "2424928  2010.0  ...           0\n",
      "2424949  2010.0  ...           1\n",
      "2424950  2010.0  ...           1\n",
      "2424953  2010.0  ...           1\n",
      "...         ...  ...         ...\n",
      "5470026  2010.0  ...           1\n",
      "5470029  2010.0  ...           1\n",
      "5470077  2010.0  ...           0\n",
      "5470086  2010.0  ...           0\n",
      "5470094  2010.0  ...           1\n",
      "\n",
      "[92236 rows x 14 columns], 'a1a63667780cb7392e35539ec39715c9', 0, 2, '_partitions', Empty DataFrame\n",
      "Columns: [year, geometry, class, tree_type, essence, dataset, index_right, start_date, end_date, cause, notes, area, sd, _partitions]\n",
      "Index: [], {0, 1})\n",
      "kwargs:    {}\n",
      "Exception: \"RuntimeError('shuffle_transfer failed during shuffle a1a63667780cb7392e35539ec39715c9')\"\n",
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shuffle_transfer failed during shuffle a1a63667780cb7392e35539ec39715c9",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mArrowTypeError\u001b[0m                            Traceback (most recent call last)",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/distributed/shuffle/_shuffle.py:62\u001b[0m, in \u001b[0;36mshuffle_transfer\u001b[0;34m()\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 62\u001b[0m     \u001b[39mreturn\u001b[39;00m get_worker_plugin()\u001b[39m.\u001b[39madd_partition(\n\u001b[1;32m     63\u001b[0m         \u001b[39minput\u001b[39m,\n\u001b[1;32m     64\u001b[0m         input_partition,\n\u001b[1;32m     65\u001b[0m         spec\u001b[39m=\u001b[39mDataFrameShuffleSpec(\n\u001b[1;32m     66\u001b[0m             \u001b[39mid\u001b[39m\u001b[39m=\u001b[39m\u001b[39mid\u001b[39m,\n\u001b[1;32m     67\u001b[0m             npartitions\u001b[39m=\u001b[39mnpartitions,\n\u001b[1;32m     68\u001b[0m             column\u001b[39m=\u001b[39mcolumn,\n\u001b[1;32m     69\u001b[0m             meta\u001b[39m=\u001b[39mmeta,\n\u001b[1;32m     70\u001b[0m             parts_out\u001b[39m=\u001b[39mparts_out,\n\u001b[1;32m     71\u001b[0m         ),\n\u001b[1;32m     72\u001b[0m     )\n\u001b[1;32m     73\u001b[0m \u001b[39mexcept\u001b[39;00m ShuffleClosedError:\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/distributed/shuffle/_worker_plugin.py:140\u001b[0m, in \u001b[0;36madd_partition\u001b[0;34m()\u001b[0m\n\u001b[1;32m    139\u001b[0m shuffle \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_or_create_shuffle(spec)\n\u001b[0;32m--> 140\u001b[0m \u001b[39mreturn\u001b[39;00m sync(\n\u001b[1;32m    141\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworker\u001b[39m.\u001b[39mloop,\n\u001b[1;32m    142\u001b[0m     shuffle\u001b[39m.\u001b[39madd_partition,\n\u001b[1;32m    143\u001b[0m     data\u001b[39m=\u001b[39mdata,\n\u001b[1;32m    144\u001b[0m     partition_id\u001b[39m=\u001b[39mpartition_id,\n\u001b[1;32m    145\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    146\u001b[0m )\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/distributed/utils.py:426\u001b[0m, in \u001b[0;36msync\u001b[0;34m()\u001b[0m\n\u001b[1;32m    425\u001b[0m     typ, exc, tb \u001b[39m=\u001b[39m error\n\u001b[0;32m--> 426\u001b[0m     \u001b[39mraise\u001b[39;00m exc\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[1;32m    427\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/distributed/utils.py:399\u001b[0m, in \u001b[0;36mf\u001b[0;34m()\u001b[0m\n\u001b[1;32m    398\u001b[0m     future \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mensure_future(future)\n\u001b[0;32m--> 399\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39myield\u001b[39;00m future\n\u001b[1;32m    400\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/tornado/gen.py:767\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m    766\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 767\u001b[0m     value \u001b[39m=\u001b[39m future\u001b[39m.\u001b[39mresult()\n\u001b[1;32m    768\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    769\u001b[0m     \u001b[39m# Save the exception for later. It's important that\u001b[39;00m\n\u001b[1;32m    770\u001b[0m     \u001b[39m# gen.throw() not be called inside this try/except block\u001b[39;00m\n\u001b[1;32m    771\u001b[0m     \u001b[39m# because that makes sys.exc_info behave unexpectedly.\u001b[39;00m\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/distributed/shuffle/_shuffle.py:476\u001b[0m, in \u001b[0;36madd_partition\u001b[0;34m()\u001b[0m\n\u001b[1;32m    474\u001b[0m     \u001b[39mreturn\u001b[39;00m out\n\u001b[0;32m--> 476\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffload(_)\n\u001b[1;32m    477\u001b[0m \u001b[39mawait\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_write_to_comm(out)\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/distributed/shuffle/_core.py:117\u001b[0m, in \u001b[0;36moffload\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtime(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 117\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mawait\u001b[39;00m asyncio\u001b[39m.\u001b[39mget_running_loop()\u001b[39m.\u001b[39mrun_in_executor(\n\u001b[1;32m    118\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexecutor,\n\u001b[1;32m    119\u001b[0m         func,\n\u001b[1;32m    120\u001b[0m         \u001b[39m*\u001b[39margs,\n\u001b[1;32m    121\u001b[0m     )\n",
      "File \u001b[0;32m/Library/Developer/CommandLineTools/Library/Frameworks/Python3.framework/Versions/3.9/lib/python3.9/concurrent/futures/thread.py:52\u001b[0m, in \u001b[0;36mrun\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfn(\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mkwargs)\n\u001b[1;32m     53\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m exc:\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/distributed/shuffle/_shuffle.py:467\u001b[0m, in \u001b[0;36m_\u001b[0;34m()\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mdict\u001b[39m[\u001b[39mstr\u001b[39m, \u001b[39mtuple\u001b[39m[\u001b[39mint\u001b[39m, \u001b[39mbytes\u001b[39m]]:\n\u001b[0;32m--> 467\u001b[0m     out \u001b[39m=\u001b[39m split_by_worker(\n\u001b[1;32m    468\u001b[0m         data,\n\u001b[1;32m    469\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumn,\n\u001b[1;32m    470\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmeta,\n\u001b[1;32m    471\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mworker_for,\n\u001b[1;32m    472\u001b[0m     )\n\u001b[1;32m    473\u001b[0m     out \u001b[39m=\u001b[39m {k: (partition_id, serialize_table(t)) \u001b[39mfor\u001b[39;00m k, t \u001b[39min\u001b[39;00m out\u001b[39m.\u001b[39mitems()}\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/distributed/shuffle/_shuffle.py:304\u001b[0m, in \u001b[0;36msplit_by_worker\u001b[0;34m()\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[39m# assert len(df) == nrows  # Not true if some outputs aren't wanted\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \u001b[39m# FIXME: If we do not preserve the index something is corrupting the\u001b[39;00m\n\u001b[1;32m    303\u001b[0m \u001b[39m# bytestream such that it cannot be deserialized anymore\u001b[39;00m\n\u001b[0;32m--> 304\u001b[0m t \u001b[39m=\u001b[39m to_pyarrow_table_dispatch(df, preserve_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    305\u001b[0m t \u001b[39m=\u001b[39m t\u001b[39m.\u001b[39msort_by(\u001b[39m\"\u001b[39m\u001b[39m_worker\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/dask/utils.py:642\u001b[0m, in \u001b[0;36m__call__\u001b[0;34m()\u001b[0m\n\u001b[1;32m    641\u001b[0m meth \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdispatch(\u001b[39mtype\u001b[39m(arg))\n\u001b[0;32m--> 642\u001b[0m \u001b[39mreturn\u001b[39;00m meth(arg, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/dask/dataframe/backends.py:223\u001b[0m, in \u001b[0;36mget_pyarrow_table_from_pandas\u001b[0;34m()\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpyarrow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpa\u001b[39;00m\n\u001b[0;32m--> 223\u001b[0m \u001b[39mreturn\u001b[39;00m pa\u001b[39m.\u001b[39mTable\u001b[39m.\u001b[39mfrom_pandas(obj, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/pyarrow/table.pxi:3762\u001b[0m, in \u001b[0;36mpyarrow.lib.Table.from_pandas\u001b[0;34m()\u001b[0m\n\u001b[1;32m   3761\u001b[0m from pyarrow.pandas_compat import dataframe_to_arrays\n\u001b[0;32m-> 3762\u001b[0m arrays, schema, n_rows = dataframe_to_arrays(\n\u001b[1;32m   3763\u001b[0m     df,\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/pyarrow/pandas_compat.py:611\u001b[0m, in \u001b[0;36mdataframe_to_arrays\u001b[0;34m()\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[39mif\u001b[39;00m nthreads \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 611\u001b[0m     arrays \u001b[39m=\u001b[39m [convert_column(c, f)\n\u001b[1;32m    612\u001b[0m               \u001b[39mfor\u001b[39;00m c, f \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(columns_to_convert, convert_fields)]\n\u001b[1;32m    613\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/pyarrow/pandas_compat.py:611\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    610\u001b[0m \u001b[39mif\u001b[39;00m nthreads \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m--> 611\u001b[0m     arrays \u001b[39m=\u001b[39m [convert_column(c, f)\n\u001b[1;32m    612\u001b[0m               \u001b[39mfor\u001b[39;00m c, f \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(columns_to_convert, convert_fields)]\n\u001b[1;32m    613\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/pyarrow/pandas_compat.py:598\u001b[0m, in \u001b[0;36mconvert_column\u001b[0;34m()\u001b[0m\n\u001b[1;32m    596\u001b[0m     e\u001b[39m.\u001b[39margs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mConversion failed for column \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m with type \u001b[39m\u001b[39m{!s}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    597\u001b[0m                \u001b[39m.\u001b[39mformat(col\u001b[39m.\u001b[39mname, col\u001b[39m.\u001b[39mdtype),)\n\u001b[0;32m--> 598\u001b[0m     \u001b[39mraise\u001b[39;00m e\n\u001b[1;32m    599\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m field_nullable \u001b[39mand\u001b[39;00m result\u001b[39m.\u001b[39mnull_count \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/pyarrow/pandas_compat.py:592\u001b[0m, in \u001b[0;36mconvert_column\u001b[0;34m()\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 592\u001b[0m     result \u001b[39m=\u001b[39m pa\u001b[39m.\u001b[39marray(col, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39mtype_, from_pandas\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, safe\u001b[39m=\u001b[39msafe)\n\u001b[1;32m    593\u001b[0m \u001b[39mexcept\u001b[39;00m (pa\u001b[39m.\u001b[39mArrowInvalid,\n\u001b[1;32m    594\u001b[0m         pa\u001b[39m.\u001b[39mArrowNotImplementedError,\n\u001b[1;32m    595\u001b[0m         pa\u001b[39m.\u001b[39mArrowTypeError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/pyarrow/array.pxi:323\u001b[0m, in \u001b[0;36mpyarrow.lib.array\u001b[0;34m()\u001b[0m\n\u001b[1;32m    322\u001b[0m         values, obj.dtype, type)\n\u001b[0;32m--> 323\u001b[0m result = _ndarray_to_array(values, mask, type, c_from_pandas, safe,\n\u001b[1;32m    324\u001b[0m                            pool)\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/pyarrow/array.pxi:79\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_array\u001b[0;34m()\u001b[0m\n\u001b[1;32m     78\u001b[0m shared_ptr[CChunkedArray] chunked_out\n\u001b[0;32m---> 79\u001b[0m shared_ptr[CDataType] c_type = _ndarray_to_type(values, type)\n\u001b[1;32m     80\u001b[0m CCastOptions cast_options = CCastOptions(safe)\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/pyarrow/array.pxi:67\u001b[0m, in \u001b[0;36mpyarrow.lib._ndarray_to_type\u001b[0;34m()\u001b[0m\n\u001b[1;32m     66\u001b[0m with nogil:\n\u001b[0;32m---> 67\u001b[0m     check_status(NumPyDtypeToArrow(dtype, &c_type))\n\u001b[1;32m     68\u001b[0m \n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/pyarrow/error.pxi:123\u001b[0m, in \u001b[0;36mpyarrow.lib.check_status\u001b[0;34m()\u001b[0m\n\u001b[1;32m    122\u001b[0m elif status.IsTypeError():\n\u001b[0;32m--> 123\u001b[0m     raise ArrowTypeError(message)\n\u001b[1;32m    124\u001b[0m elif status.IsCapacityError():\n",
      "\u001b[0;31mArrowTypeError\u001b[0m: ('Did not pass numpy.dtype object', 'Conversion failed for column geometry with type geometry')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/arthurcalvi/Repo/Disturbance-Attribution-Dataset-Joining/join-datasets/temporo-spatial-join.ipynb Cell 21\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurcalvi/Repo/Disturbance-Attribution-Dataset-Joining/join-datasets/temporo-spatial-join.ipynb#X23sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdask\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdiagnostics\u001b[39;00m \u001b[39mimport\u001b[39;00m ProgressBar\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/arthurcalvi/Repo/Disturbance-Attribution-Dataset-Joining/join-datasets/temporo-spatial-join.ipynb#X23sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m \u001b[39mwith\u001b[39;00m ProgressBar():\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/arthurcalvi/Repo/Disturbance-Attribution-Dataset-Joining/join-datasets/temporo-spatial-join.ipynb#X23sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     gr \u001b[39m=\u001b[39m dd\u001b[39m.\u001b[39;49mconcat([senfseidl_year_pd, co_pd], axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mgroupby(by\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mindex_right\u001b[39;49m\u001b[39m'\u001b[39;49m)\u001b[39m.\u001b[39;49mapply(wrapper, meta\u001b[39m=\u001b[39;49mmeta)\u001b[39m.\u001b[39;49mcompute()\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/dask/base.py:342\u001b[0m, in \u001b[0;36mDaskMethodsMixin.compute\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcompute\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    319\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute this dask collection\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \n\u001b[1;32m    321\u001b[0m \u001b[39m    This turns a lazy Dask collection into its in-memory equivalent.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[39m    dask.compute\u001b[39;00m\n\u001b[1;32m    341\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 342\u001b[0m     (result,) \u001b[39m=\u001b[39m compute(\u001b[39mself\u001b[39;49m, traverse\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    343\u001b[0m     \u001b[39mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/dask/base.py:628\u001b[0m, in \u001b[0;36mcompute\u001b[0;34m(traverse, optimize_graph, scheduler, get, *args, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m     postcomputes\u001b[39m.\u001b[39mappend(x\u001b[39m.\u001b[39m__dask_postcompute__())\n\u001b[1;32m    627\u001b[0m \u001b[39mwith\u001b[39;00m shorten_traceback():\n\u001b[0;32m--> 628\u001b[0m     results \u001b[39m=\u001b[39m schedule(dsk, keys, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    630\u001b[0m \u001b[39mreturn\u001b[39;00m repack([f(r, \u001b[39m*\u001b[39ma) \u001b[39mfor\u001b[39;00m r, (f, a) \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(results, postcomputes)])\n",
      "File \u001b[0;32m~/Venv/DiAtDaJo/lib/python3.9/site-packages/distributed/shuffle/_shuffle.py:76\u001b[0m, in \u001b[0;36mshuffle_transfer\u001b[0;34m()\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[39mraise\u001b[39;00m Reschedule()\n\u001b[1;32m     75\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m---> 76\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mshuffle_transfer failed during shuffle \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mid\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shuffle_transfer failed during shuffle a1a63667780cb7392e35539ec39715c9"
     ]
    }
   ],
   "source": [
    "dtypes = {'year': 'float64',\n",
    " 'geometry': 'geometry',\n",
    " 'class': 'object',\n",
    " 'tree_type': 'object',\n",
    " 'essence': 'object',\n",
    " 'dataset': 'object',\n",
    " 'index_right': 'int64',\n",
    " 'start_date': 'datetime64[ns]',\n",
    " 'end_date': 'datetime64[ns]',\n",
    " 'cause': 'string',\n",
    " 'notes': 'string',\n",
    " 'area': 'float64',\n",
    " 'sd': 'float64',\n",
    " 'sw': 'float64',\n",
    " 'td': 'float64',\n",
    " 'tw': 'float64',\n",
    " 'tc': 'float64',\n",
    " 'oa': 'float64',\n",
    " 'p': 'float64'}\n",
    "\n",
    "meta = pd.DataFrame(columns=dtypes.keys()).astype(dtypes)\n",
    "co_pd = pd.DataFrame(co)\n",
    "senfseidl_year_pd = pd.DataFrame(senfseidl_year.loc[all_index_right])\n",
    "from dask.diagnostics import ProgressBar\n",
    "with ProgressBar():\n",
    "    gr = dd.concat([senfseidl_year_pd, co_pd], axis=0).groupby(by='index_right').apply(wrapper, meta=meta).compute()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Méthode 2 : Merge -> Map partition\n",
    "\n",
    "30s / year\n",
    "\n",
    "40 year ~ 20min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = pd.merge(concatenation, senfseidl_year, left_on='index_right', right_index=True)\n",
    "drop = ['geometry_y', 'class_y', 'dataset_y', 'index_right_y', 'index_right_x']\n",
    "merge = merge.drop(columns=drop)\n",
    "rename = {c: c.split('_x')[0] for c in merge.columns}\n",
    "merge = merge.rename(columns=rename).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:8787/status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthurcalvi/Venv/DiAtDaJo/lib/python3.9/site-packages/distributed/client.py:3148: UserWarning: Sending large graph of size 398.86 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#~ 30s \n",
    "\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client() \n",
    "print(client.dashboard_link) \n",
    "dd_merge = dd.from_pandas(merge.reset_index(), npartitions=10)\n",
    "\n",
    "from dask.diagnostics import ProgressBar\n",
    "import traceback\n",
    "meta = {'sd': 'float64',\n",
    "        'sw': 'float64',\n",
    "        'td': 'float64',\n",
    "        'tw': 'float64',\n",
    "        'tc': 'float64',\n",
    "        'oa': 'float64',\n",
    "        'p': 'float64'}\n",
    "\n",
    "def get_prob(df):\n",
    "    return df.apply(compute_weight_on_merge, axis=1, result_type='expand')\n",
    "    \n",
    "# try: \n",
    "with ProgressBar():\n",
    "    results = dd_merge.map_partitions(get_prob, meta=meta, enforce_metadata=False).compute()\n",
    "#     raise Exception(\"ERROR HERE\") # Some code that caused the exception/error\n",
    "# except:\n",
    "#     traceback.print_exc()\n",
    "\n",
    "results.columns = ['sd', 'sw', 'td', 'tw', 'tc', 'oa', 'p']\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge = merge.drop(columns=['sd'])\n",
    "disturbances = pd.concat([merge, results], axis=1)\n",
    "disturbances.rename(columns={'index_right': 'index_ref'}, inplace=True)\n",
    "disturbances.drop(columns=['year_y', 'tree_type_y', 'essence_y'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>index_ref</th>\n",
       "      <th>year</th>\n",
       "      <th>geometry</th>\n",
       "      <th>class</th>\n",
       "      <th>tree_type</th>\n",
       "      <th>essence</th>\n",
       "      <th>dataset</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>cause</th>\n",
       "      <th>notes</th>\n",
       "      <th>area</th>\n",
       "      <th>sd</th>\n",
       "      <th>sw</th>\n",
       "      <th>td</th>\n",
       "      <th>tw</th>\n",
       "      <th>tc</th>\n",
       "      <th>oa</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2424927</td>\n",
       "      <td>2424927</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>POLYGON ((318824.872 6257012.037, 318794.980 6...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>larch</td>\n",
       "      <td>senfseidl</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>716</td>\n",
       "      <td>2424927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((306824.713 6263439.296, 324087.178 6...</td>\n",
       "      <td>Storm</td>\n",
       "      <td>mixed</td>\n",
       "      <td>broadleaves and conifers (conifers: 51 to 89%)</td>\n",
       "      <td>dfde</td>\n",
       "      <td>2009-01-24</td>\n",
       "      <td>2009-01-24</td>\n",
       "      <td>Wind</td>\n",
       "      <td>Klaus storm - area: area affected by the storm...</td>\n",
       "      <td>9.504405e+10</td>\n",
       "      <td>8.808347</td>\n",
       "      <td>0.132406</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.569706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>717</td>\n",
       "      <td>2424927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((306824.713 6263439.296, 324087.178 6...</td>\n",
       "      <td>Storm</td>\n",
       "      <td>broadleaf</td>\n",
       "      <td>broadleaves</td>\n",
       "      <td>dfde</td>\n",
       "      <td>2009-01-24</td>\n",
       "      <td>2009-01-24</td>\n",
       "      <td>Wind</td>\n",
       "      <td>Klaus storm</td>\n",
       "      <td>9.504405e+10</td>\n",
       "      <td>8.808347</td>\n",
       "      <td>0.132406</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.490540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>718</td>\n",
       "      <td>2424927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((306824.713 6263439.296, 324087.178 6...</td>\n",
       "      <td>Storm</td>\n",
       "      <td>conifer</td>\n",
       "      <td>conifers</td>\n",
       "      <td>dfde</td>\n",
       "      <td>2009-01-24</td>\n",
       "      <td>2009-01-24</td>\n",
       "      <td>Wind</td>\n",
       "      <td>Klaus storm</td>\n",
       "      <td>9.504405e+10</td>\n",
       "      <td>8.808347</td>\n",
       "      <td>0.132406</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.490540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>719</td>\n",
       "      <td>2424927</td>\n",
       "      <td>NaN</td>\n",
       "      <td>POLYGON ((306824.713 6263439.296, 324087.178 6...</td>\n",
       "      <td>Storm</td>\n",
       "      <td>conifer</td>\n",
       "      <td>maritime pine</td>\n",
       "      <td>dfde</td>\n",
       "      <td>2009-01-24</td>\n",
       "      <td>2009-01-24</td>\n",
       "      <td>Wind</td>\n",
       "      <td>Klaus storm</td>\n",
       "      <td>9.504405e+10</td>\n",
       "      <td>8.808347</td>\n",
       "      <td>0.132406</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.490540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446649</th>\n",
       "      <td>5470086</td>\n",
       "      <td>5470086</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>POLYGON ((1215037.117 6116545.426, 1214947.610...</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Conifer</td>\n",
       "      <td>laricio pine, black pine</td>\n",
       "      <td>senfseidl</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446650</th>\n",
       "      <td>23359</td>\n",
       "      <td>5470086</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>POINT (1215621.207 6116339.642)</td>\n",
       "      <td>Biotic</td>\n",
       "      <td>conifer</td>\n",
       "      <td>Pines</td>\n",
       "      <td>hm</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Erodé</td>\n",
       "      <td>Parquet en régénération - PLC au stade gaulis ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.619281</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446651</th>\n",
       "      <td>5470094</td>\n",
       "      <td>5470094</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>POLYGON ((1210124.853 6138064.278, 1210154.685...</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Mixed</td>\n",
       "      <td>mixed,maritime pine</td>\n",
       "      <td>senfseidl</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.880000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446652</th>\n",
       "      <td>17383</td>\n",
       "      <td>5470094</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>POINT (1209622.093 6139189.644)</td>\n",
       "      <td>Biotic</td>\n",
       "      <td>conifer</td>\n",
       "      <td>Pines</td>\n",
       "      <td>hm</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Cochenille du pin maritime</td>\n",
       "      <td>Foyer actif de Matsucoccus Feytaudii avec fort...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.091095</td>\n",
       "      <td>0.989878</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.696964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446653</th>\n",
       "      <td>22660</td>\n",
       "      <td>5470094</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>POINT (1209825.333 6138714.404)</td>\n",
       "      <td>Other</td>\n",
       "      <td>conifer</td>\n",
       "      <td>Pines</td>\n",
       "      <td>hm</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dégât dû à un traitement chimique</td>\n",
       "      <td>Bosquet de pins isolés. Deux pins sur six sont...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.576048</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>446654 rows × 20 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          index  index_ref    year  \\\n",
       "0       2424927    2424927  2010.0   \n",
       "1           716    2424927     NaN   \n",
       "2           717    2424927     NaN   \n",
       "3           718    2424927     NaN   \n",
       "4           719    2424927     NaN   \n",
       "...         ...        ...     ...   \n",
       "446649  5470086    5470086  2010.0   \n",
       "446650    23359    5470086  2013.0   \n",
       "446651  5470094    5470094  2010.0   \n",
       "446652    17383    5470094  2012.0   \n",
       "446653    22660    5470094  2013.0   \n",
       "\n",
       "                                                 geometry   class  tree_type  \\\n",
       "0       POLYGON ((318824.872 6257012.037, 318794.980 6...   Other      Mixed   \n",
       "1       POLYGON ((306824.713 6263439.296, 324087.178 6...   Storm      mixed   \n",
       "2       POLYGON ((306824.713 6263439.296, 324087.178 6...   Storm  broadleaf   \n",
       "3       POLYGON ((306824.713 6263439.296, 324087.178 6...   Storm    conifer   \n",
       "4       POLYGON ((306824.713 6263439.296, 324087.178 6...   Storm    conifer   \n",
       "...                                                   ...     ...        ...   \n",
       "446649  POLYGON ((1215037.117 6116545.426, 1214947.610...    Fire    Conifer   \n",
       "446650                    POINT (1215621.207 6116339.642)  Biotic    conifer   \n",
       "446651  POLYGON ((1210124.853 6138064.278, 1210154.685...    Fire      Mixed   \n",
       "446652                    POINT (1209622.093 6139189.644)  Biotic    conifer   \n",
       "446653                    POINT (1209825.333 6138714.404)   Other    conifer   \n",
       "\n",
       "                                               essence    dataset start_date  \\\n",
       "0                                                larch  senfseidl        NaT   \n",
       "1       broadleaves and conifers (conifers: 51 to 89%)       dfde 2009-01-24   \n",
       "2                                          broadleaves       dfde 2009-01-24   \n",
       "3                                             conifers       dfde 2009-01-24   \n",
       "4                                        maritime pine       dfde 2009-01-24   \n",
       "...                                                ...        ...        ...   \n",
       "446649                        laricio pine, black pine  senfseidl        NaT   \n",
       "446650                                           Pines         hm        NaT   \n",
       "446651                             mixed,maritime pine  senfseidl        NaT   \n",
       "446652                                           Pines         hm        NaT   \n",
       "446653                                           Pines         hm        NaT   \n",
       "\n",
       "         end_date                              cause  \\\n",
       "0             NaT                               <NA>   \n",
       "1      2009-01-24                               Wind   \n",
       "2      2009-01-24                               Wind   \n",
       "3      2009-01-24                               Wind   \n",
       "4      2009-01-24                               Wind   \n",
       "...           ...                                ...   \n",
       "446649        NaT                               <NA>   \n",
       "446650        NaT                              Erodé   \n",
       "446651        NaT                               <NA>   \n",
       "446652        NaT         Cochenille du pin maritime   \n",
       "446653        NaT  Dégât dû à un traitement chimique   \n",
       "\n",
       "                                                    notes          area  \\\n",
       "0                                                    <NA>           NaN   \n",
       "1       Klaus storm - area: area affected by the storm...  9.504405e+10   \n",
       "2                                             Klaus storm  9.504405e+10   \n",
       "3                                             Klaus storm  9.504405e+10   \n",
       "4                                             Klaus storm  9.504405e+10   \n",
       "...                                                   ...           ...   \n",
       "446649                                               <NA>           NaN   \n",
       "446650  Parquet en régénération - PLC au stade gaulis ...           NaN   \n",
       "446651                                               <NA>           NaN   \n",
       "446652  Foyer actif de Matsucoccus Feytaudii avec fort...           NaN   \n",
       "446653  Bosquet de pins isolés. Deux pins sur six sont...           NaN   \n",
       "\n",
       "              sd        sw   td        tw    tc    oa         p  \n",
       "0       0.000000  1.000000  0.0  1.000000  1.00  0.88  0.880000  \n",
       "1       8.808347  0.132406  1.0  0.916667  0.75  0.95  0.569706  \n",
       "2       8.808347  0.132406  1.0  0.916667  0.50  0.95  0.490540  \n",
       "3       8.808347  0.132406  1.0  0.916667  0.50  0.95  0.490540  \n",
       "4       8.808347  0.132406  1.0  0.916667  0.50  0.95  0.490540  \n",
       "...          ...       ...  ...       ...   ...   ...       ...  \n",
       "446649  0.000000  1.000000  0.0  1.000000  1.00  0.88  0.880000  \n",
       "446650  0.619281  1.000000  3.0  0.750000  0.75  0.90  0.750000  \n",
       "446651  0.000000  1.000000  0.0  1.000000  1.00  0.88  0.880000  \n",
       "446652  1.091095  0.989878  2.0  0.833333  0.50  0.90  0.696964  \n",
       "446653  0.576048  1.000000  3.0  0.750000  0.50  0.90  0.675000  \n",
       "\n",
       "[446654 rows x 20 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disturbances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = disturbances.groupby(by='index_ref')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_proba_per_class(gdf):\n",
    "    dclasses = {}\n",
    "    present_classes = [ k for k in gdf['class'].unique() if k != 'Other']\n",
    "    if present_classes == []:\n",
    "        return {'Other': gdf['p'].mean()}\n",
    "\n",
    "    for c in [k for k,v in dict_isin.items() if set(v).intersection(set(present_classes))]:\n",
    "        cond = gdf['class'].isin(dict_isin[c])\n",
    "        for_ = gdf[cond]['p'].sum()\n",
    "        against_ = gdf[~cond]['p'].sum()\n",
    "        dclasses[c] = (for_ - against_) / len(gdf)\n",
    "\n",
    "    return dclasses \n",
    "\n",
    "def compute_class_p_spread(d):\n",
    "    #sort dict by value descending \n",
    "    d = {k: v for k, v in sorted(d.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "    keys = list(d.keys()) \n",
    "    values = list(d.values())\n",
    "\n",
    "    spread = values[0] - values[1] if len(values) > 1 else np.nan \n",
    "\n",
    "    return keys[0], values[0], spread\n",
    "\n",
    "def wrapper_class_proba_spread(group):\n",
    "    dclasses = compute_proba_per_class(group)\n",
    "    max_key, max_value, spread = compute_class_p_spread(dclasses)\n",
    "    #return dataframe with index\n",
    "    return pd.DataFrame({'class': max_key, 'p': max_value, 'spread': spread}, index=group.index[[0]]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import islice\n",
    "for name, group in islice(groups, 100):\n",
    "    wrapper_class_proba_spread(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>index_ref</th>\n",
       "      <th>year</th>\n",
       "      <th>geometry</th>\n",
       "      <th>class</th>\n",
       "      <th>tree_type</th>\n",
       "      <th>essence</th>\n",
       "      <th>dataset</th>\n",
       "      <th>start_date</th>\n",
       "      <th>end_date</th>\n",
       "      <th>cause</th>\n",
       "      <th>notes</th>\n",
       "      <th>area</th>\n",
       "      <th>sd</th>\n",
       "      <th>sw</th>\n",
       "      <th>td</th>\n",
       "      <th>tw</th>\n",
       "      <th>tc</th>\n",
       "      <th>oa</th>\n",
       "      <th>p</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>2425266</td>\n",
       "      <td>2425266</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>POLYGON ((216638.494 6792249.478, 216578.666 6...</td>\n",
       "      <td>Other</td>\n",
       "      <td>Broadleaf</td>\n",
       "      <td>broadleaf</td>\n",
       "      <td>senfseidl</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>11922</td>\n",
       "      <td>2425266</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>POINT (216764.134 6791334.000)</td>\n",
       "      <td>Other</td>\n",
       "      <td>broadleaf</td>\n",
       "      <td>Oaks</td>\n",
       "      <td>hm</td>\n",
       "      <td>NaT</td>\n",
       "      <td>NaT</td>\n",
       "      <td>Dégât dû au gel</td>\n",
       "      <td>Dégats important sur l',ensemble des quadrats ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.924059</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.825</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       index  index_ref    year  \\\n",
       "186  2425266    2425266  2010.0   \n",
       "187    11922    2425266  2010.0   \n",
       "\n",
       "                                              geometry  class  tree_type  \\\n",
       "186  POLYGON ((216638.494 6792249.478, 216578.666 6...  Other  Broadleaf   \n",
       "187                     POINT (216764.134 6791334.000)  Other  broadleaf   \n",
       "\n",
       "       essence    dataset start_date end_date            cause  \\\n",
       "186  broadleaf  senfseidl        NaT      NaT             <NA>   \n",
       "187       Oaks         hm        NaT      NaT  Dégât dû au gel   \n",
       "\n",
       "                                                 notes  area        sd   sw  \\\n",
       "186                                               <NA>   NaN  0.000000  1.0   \n",
       "187  Dégats important sur l',ensemble des quadrats ...   NaN  0.924059  1.0   \n",
       "\n",
       "      td   tw    tc    oa      p  \n",
       "186  0.0  1.0  1.00  0.88  0.880  \n",
       "187  0.0  1.0  0.75  0.90  0.825  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>p</th>\n",
       "      <th>spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>Biotic-dieback</td>\n",
       "      <td>0.805748</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              class         p  spread\n",
       "268  Biotic-dieback  0.805748     0.0"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wrapper_class_proba_spread(group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Other': 0.8525}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = compute_proba_per_class(group)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Other', 0.8525, nan)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_class_p_spread(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthurcalvi/Venv/DiAtDaJo/lib/python3.9/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\n",
      "Perhaps you already have a cluster running?\n",
      "Hosting the HTTP server on port 52831 instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://127.0.0.1:52831/status\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/arthurcalvi/Venv/DiAtDaJo/lib/python3.9/site-packages/distributed/client.py:3148: UserWarning: Sending large graph of size 27.95 MiB.\n",
      "This may cause some slowdown.\n",
      "Consider scattering data ahead of time and using futures.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#92000 -> >10min (pd)\n",
    "#92000 -> 6min (dd groupby apply)\n",
    "#92000 -> 4min (dd map_partitions) but issue on the index\n",
    "\n",
    "client = Client() \n",
    "print(client.dashboard_link) \n",
    "\n",
    "\n",
    "r_ = dd.from_pandas(disturbances[['index_ref', 'class', 'sd', 'sw', 'td', 'tw', 'tc', 'oa', 'p']], npartitions=10)\n",
    "\n",
    "dtypes = {\n",
    "    'class': 'string',\n",
    "    'p': 'float64',\n",
    "    'spread': 'float64'\n",
    "}\n",
    "\n",
    "# with ProgressBar():\n",
    "#     r = r_.groupby(by='index_ref').apply(wrapper_class_proba_spread, meta=meta).compute()\n",
    "# client.close()\n",
    "\n",
    "r = r_.map_partitions(lambda df: df.groupby('index_ref',as_index=True).apply(wrapper_class_proba_spread), meta=meta).compute()\n",
    "client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92236"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(disturbances.groupby(by='index_ref').groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>p</th>\n",
       "      <th>spread</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index_ref</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2424927</th>\n",
       "      <th>0</th>\n",
       "      <td>Storm</td>\n",
       "      <td>0.083111</td>\n",
       "      <td>0.166223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424928</th>\n",
       "      <th>6</th>\n",
       "      <td>Storm</td>\n",
       "      <td>0.097208</td>\n",
       "      <td>0.194416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424949</th>\n",
       "      <th>12</th>\n",
       "      <td>Storm</td>\n",
       "      <td>0.082907</td>\n",
       "      <td>0.165813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424950</th>\n",
       "      <th>18</th>\n",
       "      <td>Storm</td>\n",
       "      <td>0.232265</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2424953</th>\n",
       "      <th>23</th>\n",
       "      <td>Storm</td>\n",
       "      <td>0.200598</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470026</th>\n",
       "      <th>446643</th>\n",
       "      <td>Fire</td>\n",
       "      <td>0.143339</td>\n",
       "      <td>0.286678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470029</th>\n",
       "      <th>446645</th>\n",
       "      <td>Fire</td>\n",
       "      <td>0.081608</td>\n",
       "      <td>0.163217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470077</th>\n",
       "      <th>446647</th>\n",
       "      <td>Fire</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470086</th>\n",
       "      <th>446649</th>\n",
       "      <td>Fire</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5470094</th>\n",
       "      <th>446651</th>\n",
       "      <td>Biotic-dieback</td>\n",
       "      <td>0.163988</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92244 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           class         p    spread\n",
       "index_ref                                           \n",
       "2424927   0                Storm  0.083111  0.166223\n",
       "2424928   6                Storm  0.097208  0.194416\n",
       "2424949   12               Storm  0.082907  0.165813\n",
       "2424950   18               Storm  0.232265       NaN\n",
       "2424953   23               Storm  0.200598       NaN\n",
       "...                          ...       ...       ...\n",
       "5470026   446643            Fire  0.143339  0.286678\n",
       "5470029   446645            Fire  0.081608  0.163217\n",
       "5470077   446647            Fire  0.065000       NaN\n",
       "5470086   446649            Fire  0.065000  0.130000\n",
       "5470094   446651  Biotic-dieback  0.163988  0.000000\n",
       "\n",
       "[92244 rows x 3 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index_ref</th>\n",
       "      <th>level_1</th>\n",
       "      <th>class</th>\n",
       "      <th>p</th>\n",
       "      <th>spread</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2424927</td>\n",
       "      <td>0</td>\n",
       "      <td>Storm</td>\n",
       "      <td>0.083111</td>\n",
       "      <td>0.166223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2424928</td>\n",
       "      <td>6</td>\n",
       "      <td>Storm</td>\n",
       "      <td>0.097208</td>\n",
       "      <td>0.194416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2424949</td>\n",
       "      <td>12</td>\n",
       "      <td>Storm</td>\n",
       "      <td>0.082907</td>\n",
       "      <td>0.165813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2424950</td>\n",
       "      <td>18</td>\n",
       "      <td>Storm</td>\n",
       "      <td>0.232265</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2424953</td>\n",
       "      <td>23</td>\n",
       "      <td>Storm</td>\n",
       "      <td>0.200598</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92239</th>\n",
       "      <td>5470026</td>\n",
       "      <td>446643</td>\n",
       "      <td>Fire</td>\n",
       "      <td>0.143339</td>\n",
       "      <td>0.286678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92240</th>\n",
       "      <td>5470029</td>\n",
       "      <td>446645</td>\n",
       "      <td>Fire</td>\n",
       "      <td>0.081608</td>\n",
       "      <td>0.163217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92241</th>\n",
       "      <td>5470077</td>\n",
       "      <td>446647</td>\n",
       "      <td>Fire</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92242</th>\n",
       "      <td>5470086</td>\n",
       "      <td>446649</td>\n",
       "      <td>Fire</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92243</th>\n",
       "      <td>5470094</td>\n",
       "      <td>446651</td>\n",
       "      <td>Biotic-dieback</td>\n",
       "      <td>0.163988</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>92236 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index_ref  level_1           class         p    spread\n",
       "0        2424927        0           Storm  0.083111  0.166223\n",
       "1        2424928        6           Storm  0.097208  0.194416\n",
       "2        2424949       12           Storm  0.082907  0.165813\n",
       "3        2424950       18           Storm  0.232265       NaN\n",
       "4        2424953       23           Storm  0.200598       NaN\n",
       "...          ...      ...             ...       ...       ...\n",
       "92239    5470026   446643            Fire  0.143339  0.286678\n",
       "92240    5470029   446645            Fire  0.081608  0.163217\n",
       "92241    5470077   446647            Fire  0.065000       NaN\n",
       "92242    5470086   446649            Fire  0.065000  0.130000\n",
       "92243    5470094   446651  Biotic-dieback  0.163988  0.000000\n",
       "\n",
       "[92236 rows x 5 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.reset_index().drop_duplicates(subset=['index_ref'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test for one year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spatial and temporal join done.\n",
      "Concatenation with reference done.\n",
      "Merging done.\n",
      "Computing weights done.\n",
      "Groupby index_ref and classification done.\n"
     ]
    }
   ],
   "source": [
    "#remove all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#full Dask -> 20s \n",
    "# with sjoin_nearest and sd computation -> 8s  \n",
    "import dask_geopandas as dgpd\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "years = senfseidl['year'].unique()\n",
    "\n",
    "temporal_buffer = 5 #years \n",
    "spatial_buffer = 5000 #meters\n",
    "\n",
    "nfi['dataset'] = 'nfi'\n",
    "hm['dataset'] = 'hm'\n",
    "dfde['dataset'] = 'dfde'\n",
    "senfseidl['dataset'] = 'senfseidl'\n",
    "\n",
    "year = 2010\n",
    "\n",
    "# SPATIAL AND TEMPORAL JOIN\n",
    "senfseidl_year = senfseidl[senfseidl['year'] == year]\n",
    "nfi_year = nfi[(nfi['start_date'].dt.year >= year - temporal_buffer) & (nfi['end_date'].dt.year <= year + temporal_buffer)]\n",
    "hm_year = hm[(hm['year'] >= year - temporal_buffer) & (hm['year'] <= year + temporal_buffer)]\n",
    "dfde_year = dfde[(dfde['start_date'].dt.year >= year - temporal_buffer) & (dfde['end_date'].dt.year <= year + temporal_buffer)]\n",
    "\n",
    "senfseidl_year_ = dgpd.from_geopandas(senfseidl_year, npartitions=10)\n",
    "dfde_year_ = dgpd.from_geopandas(dfde_year, npartitions=10)\n",
    "\n",
    "senfseidl_hm_year = hm_year.sjoin_nearest(senfseidl_year, max_distance=spatial_buffer, distance_col='sd')\n",
    "senfseidl_nfi_year = nfi_year.sjoin_nearest(senfseidl_year, max_distance=spatial_buffer, distance_col='sd')\n",
    "senfseidl_dfde_year = dfde_year_.sjoin(senfseidl_year_)\n",
    "\n",
    "#concat with dask_geopandas\n",
    "concatenation = dd.concat([senfseidl_nfi_year, senfseidl_hm_year, senfseidl_dfde_year], axis=0).compute()\n",
    "\n",
    "print('Spatial and temporal join done.')\n",
    "#CONCATENATION WITH REF\n",
    "#entire dataset -> 2.3s\n",
    "col = ['start_date', 'end_date', 'geometry', 'year_left', 'class_left', 'tree_type_left', 'essence_left', 'dataset_left', 'cause', 'notes', 'area', 'sd']\n",
    "all_index_right = concatenation['index_right'].unique()\n",
    "concatenation = concatenation[['index_right']+col]\n",
    "rename = {c: c.split('_left')[0] for c in col}\n",
    "concatenation = concatenation.rename(columns=rename)\n",
    "\n",
    "senfseidl_year['index_right'] = senfseidl_year.index\n",
    "\n",
    "#l'order of senfseidl_year and co is important. If we want to ise iloc[0] on the group to retrieve senfseidl row, we have to stick to this order.\n",
    "concatenation = dd.concat([senfseidl_year.loc[all_index_right], concatenation], axis=0).compute()\n",
    "\n",
    "print('Concatenation with reference done.')\n",
    "#MERGING\n",
    "merge = pd.merge(concatenation, senfseidl_year, left_on='index_right', right_index=True)\n",
    "drop = ['geometry_y', 'class_y', 'dataset_y', 'index_right_y', 'index_right_x']\n",
    "merge = merge.drop(columns=drop)\n",
    "rename = {c: c.split('_x')[0] for c in merge.columns}\n",
    "merge = merge.rename(columns=rename).reset_index()\n",
    "\n",
    "print('Merging done.')\n",
    "\n",
    "#COMPUTING WEIGHT\n",
    "dd_merge = dd.from_pandas(merge.reset_index(), npartitions=10)\n",
    "meta = {'sd': 'float64',\n",
    "        'sw': 'float64',\n",
    "        'td': 'float64',\n",
    "        'tw': 'float64',\n",
    "        'tc': 'float64',\n",
    "        'oa': 'float64',\n",
    "        'p': 'float64'}\n",
    "\n",
    "def get_prob(df):\n",
    "    return df.apply(compute_weight_on_merge, axis=1, result_type='expand')\n",
    "    \n",
    "\n",
    "results = dd_merge.map_partitions(get_prob, meta=meta, enforce_metadata=False).compute()\n",
    "\n",
    "\n",
    "results.columns = ['sd', 'sw', 'td', 'tw', 'tc', 'oa', 'p']\n",
    "\n",
    "\n",
    "#concatenation with weights\n",
    "merge = merge.drop(columns=['sd'])\n",
    "disturbances = pd.concat([merge, results], axis=1)\n",
    "disturbances.rename(columns={'index_right': 'index_ref'}, inplace=True)\n",
    "disturbances.drop(columns=['year_y', 'tree_type_y', 'essence_y'], inplace=True)\n",
    "\n",
    "print('Computing weights done.')\n",
    "\n",
    "#GROUPBY INDEX_REF and Classification \n",
    "r_ = dd.from_pandas(disturbances[['index_ref', 'class', 'sd', 'sw', 'td', 'tw', 'tc', 'oa', 'p']], npartitions=10)\n",
    "\n",
    "dtypes = {\n",
    "    'class': 'string',\n",
    "    'p': 'float64',\n",
    "    'spread': 'float64'\n",
    "}\n",
    "\n",
    "meta = pd.DataFrame(columns=dtypes.keys()).astype(dtypes)\n",
    "r = r_.map_partitions(lambda df: df.groupby('index_ref',as_index=True).apply(wrapper_class_proba_spread), meta=meta).compute()\n",
    "r = r.reset_index().drop_duplicates(subset=['index_ref'])\n",
    "print('Groupby index_ref and classification done.')\n",
    "\n",
    "#ATTRIBUTION CONSTRUCTION\n",
    "col_left = ['year', 'geometry', 'tree_type', 'essence']\n",
    "left = senfseidl_year.loc[all_index_right].sort_index()[col_left]\n",
    "col_right = ['index_ref', 'class', 'p', 'spread']\n",
    "right = r.sort_values(by='index_ref')[col_right]\n",
    "attribution = pd.merge(left, right, left_index=True, right_on='index_ref')\n",
    "\n",
    "print('Attribution construction done.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RUN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dask_geopandas as dgpd\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "def get_attribution_per_year(year, senfseidl, hm, nfi, dfde, temporal_buffer, spatial_buffer, outdir, verbose=0):\n",
    "\n",
    "    #TEMPORAL AND SPATIAL JOIN ~ 8s\n",
    "    senfseidl_year = senfseidl[senfseidl['year'] == year]\n",
    "    nfi_year = nfi[(nfi['start_date'].dt.year >= year - temporal_buffer) & (nfi['end_date'].dt.year <= year + temporal_buffer)]\n",
    "    hm_year = hm[(hm['year'] >= year - temporal_buffer) & (hm['year'] <= year + temporal_buffer)]\n",
    "    dfde_year = dfde[(dfde['start_date'].dt.year >= year - temporal_buffer) & (dfde['end_date'].dt.year <= year + temporal_buffer)]\n",
    "\n",
    "    senfseidl_year_ = dgpd.from_geopandas(senfseidl_year, npartitions=10)\n",
    "    dfde_year_ = dgpd.from_geopandas(dfde_year, npartitions=10)\n",
    "\n",
    "    senfseidl_hm_year = hm_year.sjoin_nearest(senfseidl_year, max_distance=spatial_buffer, distance_col='sd')\n",
    "    senfseidl_nfi_year = nfi_year.sjoin_nearest(senfseidl_year, max_distance=spatial_buffer, distance_col='sd')\n",
    "    senfseidl_dfde_year = dfde_year_.sjoin(senfseidl_year_)\n",
    "\n",
    "    #concat with dask_geopandas\n",
    "    concatenation = dd.concat([senfseidl_nfi_year, senfseidl_hm_year, senfseidl_dfde_year], axis=0).compute()\n",
    "    if verbose > 0:\n",
    "        print('Spatial and temporal join done.')\n",
    "    \n",
    "    #CONCATENATION WITH REF ~ 2s\n",
    "    col = ['start_date', 'end_date', 'geometry', 'year_left', 'class_left', 'tree_type_left', 'essence_left', 'dataset_left', 'cause', 'notes', 'area', 'sd']\n",
    "    all_index_right = concatenation['index_right'].unique()\n",
    "    concatenation = concatenation[['index_right']+col]\n",
    "    rename = {c: c.split('_left')[0] for c in col}\n",
    "    concatenation = concatenation.rename(columns=rename)\n",
    "    senfseidl_year['index_right'] = senfseidl_year.index\n",
    "\n",
    "    #l'order of senfseidl_year and co is important. If we want to ise iloc[0] on the group to retrieve senfseidl row, we have to stick to this order.\n",
    "    concatenation = dd.concat([senfseidl_year.loc[all_index_right], concatenation], axis=0).compute()\n",
    "    if verbose > 0:\n",
    "        print('Concatenation with reference done.')\n",
    "\n",
    "    #MERGING ~ 1s \n",
    "    merge = pd.merge(concatenation, senfseidl_year, left_on='index_right', right_index=True)\n",
    "    drop = ['geometry_y', 'class_y', 'dataset_y', 'index_right_y', 'index_right_x']\n",
    "    merge = merge.drop(columns=drop)\n",
    "    rename = {c: c.split('_x')[0] for c in merge.columns}\n",
    "    merge = merge.rename(columns=rename).reset_index()\n",
    "\n",
    "    if verbose > 0:\n",
    "        print('Merging done.')\n",
    "    #COMPUTING WEIGHT ~ 30s \n",
    "    dd_merge = dd.from_pandas(merge.reset_index(), npartitions=10)\n",
    "    meta = {'sd': 'float64',\n",
    "            'sw': 'float64',\n",
    "            'td': 'float64',\n",
    "            'tw': 'float64',\n",
    "            'tc': 'float64',\n",
    "            'oa': 'float64',\n",
    "            'p': 'float64'}\n",
    "\n",
    "    \n",
    "    results = dd_merge.map_partitions(get_prob, meta=meta, enforce_metadata=False).compute()\n",
    "\n",
    "\n",
    "    results.columns = ['sd', 'sw', 'td', 'tw', 'tc', 'oa', 'p']\n",
    "\n",
    "\n",
    "    #concatenation with weights\n",
    "    merge = merge.drop(columns=['sd'])\n",
    "    disturbances = pd.concat([merge, results], axis=1)\n",
    "    disturbances.rename(columns={'index_right': 'index_ref'}, inplace=True)\n",
    "    disturbances.drop(columns=['year_y', 'tree_type_y', 'essence_y'], inplace=True)\n",
    "    gpd.GeoDataFrame(disturbances, crs=epsg).to_parquet(os.path.join(outdir, f'disturbances_{year}.parquet'))\n",
    "    if verbose > 0:\n",
    "        print('Computing weights done.')\n",
    "    \n",
    "    #GROUPBY INDEX_REF and Classification ~ 4min \n",
    "    r_ = dd.from_pandas(disturbances[['index_ref', 'class', 'sd', 'sw', 'td', 'tw', 'tc', 'oa', 'p']], npartitions=10)\n",
    "    dtypes = {\n",
    "        'class': 'string',\n",
    "        'p': 'float64',\n",
    "        'spread': 'float64'\n",
    "        }\n",
    "    meta = pd.DataFrame(columns=dtypes.keys()).astype(dtypes)\n",
    "    r = r_.map_partitions(lambda df: df.groupby('index_ref',as_index=True).apply(wrapper_class_proba_spread), meta=meta).compute()\n",
    "    r = r.reset_index().drop_duplicates(subset=['index_ref'])\n",
    "    if verbose > 0:\n",
    "        print('Groupby index_ref and classification done.')\n",
    "\n",
    "    #ATTRIBUTION CONSTRUCTION ~ 1s \n",
    "    col_left = ['year', 'geometry', 'tree_type', 'essence']\n",
    "    left = senfseidl_year.loc[all_index_right].sort_index()[col_left]\n",
    "    col_right = ['index_ref', 'class', 'p', 'spread']\n",
    "    right = r.sort_values(by='index_ref')[col_right]\n",
    "    attribution = pd.merge(left, right, left_index=True, right_on='index_ref')\n",
    "    if verbose > 0:\n",
    "        print('Attribution construction done.')\n",
    "\n",
    "    #WRITING ~ 10s \n",
    "    gpd.GeoDataFrame(attribution, crs=epsg).to_parquet(os.path.join(outdir, f'attribution_{year}.parquet'))\n",
    "    return attribution\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 35/35 [3:43:20<00:00, 382.86s/it]   \n"
     ]
    }
   ],
   "source": [
    "#35y -> 223min \n",
    "\n",
    "#remove all warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm \n",
    "\n",
    "outdir = '../data/results'\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "years = senfseidl['year'].unique()\n",
    "\n",
    "temporal_buffer = 5 #years \n",
    "spatial_buffer = 5000 #meters\n",
    "\n",
    "nfi['dataset'] = 'nfi'\n",
    "hm['dataset'] = 'hm'\n",
    "dfde['dataset'] = 'dfde'\n",
    "senfseidl['dataset'] = 'senfseidl'\n",
    "\n",
    "for year in tqdm(years):\n",
    "    get_attribution_per_year(year, senfseidl, hm, nfi, dfde, temporal_buffer, spatial_buffer, outdir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DiAtDaJo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
